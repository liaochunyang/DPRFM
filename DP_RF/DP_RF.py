#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import numpy as np


# In[ ]:


def RF_Gaussian(gamma, N, x_train, x_test):
    """
    Generate Gaussian Random Features.
    
    Inputs:
    gamma: (2*gamma)**0.5 is the standard deviation of the Gaussian distribution
    N: number of random features
    x_train: training samples of shape m x d
    x_test: test samples of shape m' x d
    
    Outputs:
    A_train: Training Random Feature Map A_train
    A_test: Test random feature map A_test
    """
    # number of samples and dimension of features
    m,d = x_train.shape
    # random features generated from Cauchy distribution with scaling parameter gamma
    Omega = np.random.normal(loc=0, scale=2.0*gamma, size = (d,N))
    # Random feature matrix A
    random_offset = np.random.uniform(0, 2 * np.pi, size=(1,N))
    A_train = np.cos(x_train@Omega + random_offset)
    
    A_test = np.cos(x_test@Omega + random_offset)
    
    return A_train * (2.0 / N) ** 0.5, A_test * (2.0 / N) ** 0.5


def private(c, Delta_c, epsilon, delta, mechanism="Laplace"):
    """
    Generate private coefficients
    
    Inputs:
    c: non-private coefficient
    Delta_c: l2-sensitivity
    epsilon: privace budget
    delta: privacy parameter
    mechanism: Three different mechinisms
    
    Output:
    c_private: private coefficients
    """
    N = c.shape[0]
    
    if mechanism == "Laplace":
        
        Z = np.random.laplace(loc=0.0, scale=Delta_c/epsilon, size=c.shape)
        return c+Z
    
    elif mechanism == "Gaussian":
        
        Z = np.random.normal(loc=0.0, scale=np.sqrt(2*np.log(1.25/delta))*Delta_c/epsilon, size=c.shape)
        return c+Z
    
    elif mechanism == "Gamma":
                
        R = np.random.gamma(N, scale = Delta_c/epsilon)
        Z = np.random.normal(0, 1, size = c.shape)
        L2Lap = R * (Z / np.linalg.norm(Z))
        
        return c+L2Lap
    
def objective_perturb(epsilon, c, X, y, lamb):
    
    """
    Private estimator generated by objective perturbation.
    Inputs:
    epsilon: privacy budget
    c: upper bound of the second order derivative
    X: training inputs
    y: training labels
    lamb: regularization parameter
    Returns:
    private estimator by objective perturbation
    """
    
    m, N = X.shape
    
    if (lamb == 0) or ((epsilon - np.log(1+ 2*c/m/lamb + c**2/m**2/lamb**2))<=0):
        
        Delta = c/(m* (np.exp(epsilon/4) - 1)) - lamb
        epsilon_prime = epsilon/2
        
    else:
        
        Delta = 0
        epsilon_prime = epsilon - np.log(1+ 2*c/m/lamb + c**2/m**2/lamb**2)
        
    R = np.random.gamma(N, scale = 2/epsilon_prime)
    Z = np.random.normal(0, 1, size = (N,))
    b = R * (Z / np.linalg.norm(Z))
    
    return np.linalg.solve(2*X.T@X/m + (2*lamb+Delta) * np.identity(N), 2*X.T@y/m - b/m)

def DPRF_SGD(epsilon, delta, X, y, T, eta):
    """
    Private estimator generated by DPSGD.
    Input:
    epsilon, delta: privacy budget and parameter
    X: training data
    y: training labels
    T: number of iterations
    eta: learning rate
    Return:
    private estimator
    """
    
    m, N = X.shape
    
    c = np.zeros((N,))
    
    for i in range(T):
        
        idx = np.random.choice(m,1)[0]
        
        c = c - eta * (np.sum(c*X[idx,:]) - y[idx]) * X[idx,:]
    
    # parameters 
    C_T = max(np.sqrt(3*m*np.log(2*m/delta)/T), 3*m*np.log(2*m/delta)/T)
    Delta = 4*np.exp(1)*eta**2 * (1+np.sqrt(eta*T))**2 * T * (1+C_T) * (1+T*(1+C_T)/m) / m
    
    sigma = np.sqrt(2*np.log(2.5/delta)) * Delta / epsilon
    
    Z = np.random.normal(loc=0.0, scale=sigma, size=(N,))
    
    return c, c + Z

def add_noise(signal, SNR_dB):
    """
    Add Gaussian random noise to signal based on SNR_dB.
    """
    ## Calculate signal power
    signal_power = np.sum(signal**2) / np.size(signal)
    
    ## SNR
    snr = 10**(SNR_dB/10)
    noise_power = signal_power / snr
    
    ## generate gaussian noise
    noise = np.random.normal(loc=0.0, scale=np.sqrt(noise_power), size=signal.shape )
    
    return signal + noise
    
    
def generate_data(m, d, fun):
    """
    Generate dataset.
    """
    
    x = np.random.normal(size=(m,d))
    y = fun(x)
    
    return x, y/np.linalg.norm(y)

def fun1(X):
    
    return np.sqrt(1+np.linalg.norm(X, axis=1))

def fun2(X):
    
    return np.sum( np.exp(-abs(X)), axis=1)


def randomized_kaczmarz(A, b, x0, max_iter):
    """
    Solves the linear system Ax = b using the randomized Kaczmarz method.

    Parameters:
    A: numpy array, the coefficient matrix
    b: numpy array, the right-hand side vector
    x0: numpy array, the initial guess for the solution
    max_iter: int, the maximum number of iterations

    Returns:
    x: numpy array, the approximate solution
    """

    m, n = A.shape
    x = x0.copy()

    for _ in range(max_iter):
        # Randomly select a row
        i = np.random.randint(m)

        # Update the solution
        x = x + (b[i] - np.dot(A[i], x)) / np.linalg.norm(A[i])**2 * A[i]

    return x

